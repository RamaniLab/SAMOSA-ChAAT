{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snf2h paper analysis and figures\n",
    "\n",
    "21/09/16\n",
    "\n",
    "Code for generating supplemental figures and statistics for the Snf2h SAMOSA 2 paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average accessibility in E14\n",
    "21/09/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import socket\n",
    "from Bio import Seq, SeqIO\n",
    "\n",
    "\n",
    "if 'biochem1' in socket.gethostname():\n",
    "    dataPBase = '/avicenna/vramani/analyses/pacbio/'\n",
    "    figPBase = '/avicenna/cmcnally/pbanalysis/'\n",
    "if 'titan' in socket.gethostname():\n",
    "    dataPBase = '/data/users/goodarzilab/colin/results/pacbio/'\n",
    "if 'wynton' in socket.gethostname():\n",
    "    dataPBase = '/wynton/group/goodarzilab/ramanilab/results/pacbio/'\n",
    "if 'rumi' in socket.gethostname():\n",
    "    raise Exception('no pacbio results folder on rumi')\n",
    "    \n",
    "    \n",
    "sampleRef = pd.read_csv(dataPBase + 'sampleRef_K562_mESC.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "negSamples = [12,13]\n",
    "chrSamples = [14,15]\n",
    "posSamples = [28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accessFdic = {}\n",
    "\n",
    "for samp in tqdm([12, 13, 14, 15, 28], position=0):\n",
    "\n",
    "    with open('{0}{1}/processed/binarized/{1}_{2}_NNsingle_HMM.pickle'.format(dataPBase,\n",
    "                                                                              sampleRef['cell'][samp],\n",
    "                                                                              sampleRef['sampleName'][samp]), 'rb') as fin:\n",
    "        hmmRes = pickle.load(fin)\n",
    "        \n",
    "    zmws = list(hmmRes.keys())\n",
    "\n",
    "    accessCount = np.full(1000, 0, dtype='float')\n",
    "    contribCount = np.full(1000, 0, dtype='int')\n",
    "    \n",
    "    for z in zmws[0:24000]:\n",
    "        useM = np.nonzero(np.isfinite(hmmRes[z]))[0]\n",
    "        useM = useM[useM < 1000]\n",
    "        accessCount[useM] += hmmRes[z][useM]\n",
    "        contribCount[useM] += 1\n",
    "        \n",
    "    accessFdic[samp] = accessCount / contribCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "combdic = {'sample':[], 'rep':[], 'position':[], 'fraction':[]}\n",
    "sampShortN = {12:'E14_chromatin', 13:'E14_chromatin', 14:'E14_chromatin_methylated',\n",
    "              15:'E14_chromatin_methylated', 28:'E14_gDNA_methylated'}\n",
    "sampRep = {12:'rep1', 13:'rep2', 14:'rep1', 15:'rep2', 28:'rep1'}\n",
    "\n",
    "for samp in [12,13,14,15,28]:\n",
    "    for b in range(1000):\n",
    "        if np.isfinite(accessFdic[samp][b]):\n",
    "            combdic['sample'].append(sampShortN[samp])\n",
    "            combdic['rep'].append(sampRep[samp])\n",
    "            combdic['position'].append(b)\n",
    "            combdic['fraction'].append(accessFdic[samp][b])\n",
    "            \n",
    "combdf = pd.DataFrame(combdic)\n",
    "\n",
    "combdf.to_csv('{0}{1}/processed/e14AccessFig.csv'.format(dataPBase, sampleRef['cell'][12]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = 13\n",
    "\n",
    "with open('{0}{1}/processed/binarized/{1}_{2}_NNsingle_HMM.pickle'.format(dataPBase,\n",
    "                                                                          sampleRef['cell'][samp],\n",
    "                                                                          sampleRef['sampleName'][samp]), 'rb') as fin:\n",
    "    hmmRes = pickle.load(fin)\n",
    "        \n",
    "zmws = list(hmmRes.keys())\n",
    "usezmws = zmws[0:24000]\n",
    "\n",
    "\n",
    "inac = pd.read_csv(dataPBase + '{0}/processed/inaccessibleRegions/{0}_{1}_inacRegions.csv'.format(sampleRef['cell'][samp],\n",
    "                                                                                                  sampleRef['sampleName'][samp]), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inacWd = {}\n",
    "for samp in tqdm([12, 13, 14, 15, 28], position=0):\n",
    "\n",
    "    with open('{0}{1}/processed/binarized/{1}_{2}_NNsingle_HMM.pickle'.format(dataPBase,\n",
    "                                                                              sampleRef['cell'][samp],\n",
    "                                                                              sampleRef['sampleName'][samp]), 'rb') as fin:\n",
    "        hmmRes = pickle.load(fin)\n",
    "        \n",
    "    zmws = list(hmmRes.keys())\n",
    "    usezmws = zmws[0:24000]\n",
    "    \n",
    "    inac = pd.read_csv(dataPBase + '{0}/processed/inaccessibleRegions/{0}_{1}_inacRegions.csv'.format(sampleRef['cell'][samp],\n",
    "                                                                                                      sampleRef['sampleName'][samp]), index_col=0)\n",
    "    inacWd[samp] = inac[np.isin(inac['zmw'], usezmws)]['length'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "combdic = {'sample':[], 'rep':[], 'length':[]}\n",
    "sampShortN = {12:'E14_chromatin', 13:'E14_chromatin', 14:'E14_chromatin_methylated',\n",
    "              15:'E14_chromatin_methylated', 28:'E14_gDNA_methylated'}\n",
    "sampRep = {12:'rep1', 13:'rep2', 14:'rep1', 15:'rep2', 28:'rep1'}\n",
    "\n",
    "for samp in [12,13,14,15,28]:\n",
    "    for i in inacWd[samp]:\n",
    "        combdic['sample'].append(sampShortN[samp])\n",
    "        combdic['rep'].append(sampRep[samp])\n",
    "        combdic['length'].append(i)\n",
    "            \n",
    "combdf = pd.DataFrame(combdic)\n",
    "\n",
    "combdf.to_csv('{0}{1}/processed/e14FootprintsFig.csv'.format(dataPBase, sampleRef['cell'][12]), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R code to generate figures from these csv inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(patchwork)\n",
    "library(extrafont)\n",
    "\n",
    "theme_update(text = element_text(family=\"Arial\", size=10))\n",
    "\n",
    "accessibility <- read.csv(file=\"C:/Users/Colin/OneDrive/Ramani Lab/Data/pbanalysis/processed/e14AccessFig.csv\")\n",
    "\n",
    "\n",
    "p1 <- ggplot(accessibility, aes(x=position, y=fraction, color=sample, linetype=rep)) + \n",
    "  geom_line() +\n",
    "  labs(x=\"Distance from 5' end of molecule\",\n",
    "       y=\"Fraction of molecules that are accessible\",\n",
    "       title='Average accessibility',\n",
    "       color='Sample',\n",
    "       linetype='Replicate') +\n",
    "  theme_bw()\n",
    "\n",
    "\n",
    "footprints <- read.csv(file=\"C:/Users/Colin/OneDrive/Ramani Lab/Data/pbanalysis/processed/e14FootprintsFig.csv\")\n",
    "\n",
    "p2 <- ggplot(footprints, aes(length, color=sample, linetype=rep)) +\n",
    "  geom_freqpoly(bins=200) +\n",
    "  xlim(0,1000) +\n",
    "  labs(x='Footprint length',\n",
    "       y='Number of footprints',\n",
    "       title='Footprint size distribution',\n",
    "       color='Sample',\n",
    "       linetype='Replicate') +\n",
    "  theme_bw()\n",
    "\n",
    "\n",
    "combined <- ((p1 + p2) & theme(legend.position = \"bottom\")) + plot_layout(guides=\"collect\")\n",
    "\n",
    "#combined \n",
    "\n",
    "ggsave('C:/Users/Colin/OneDrive/Ramani Lab/Data/pbanalysis/Figures/SAMOSA2_paper/E14.png', combined, width=8, height=4, units='in', dpi=300)\n",
    "ggsave('C:/Users/Colin/OneDrive/Ramani Lab/Data/pbanalysis/Figures/SAMOSA2_paper/E14.pdf', combined, width=8, height=4, units='in', dpi=300)\n",
    "\n",
    "#dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cutoffs for nucleosome counting\n",
    "21/10/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:20<00:00,  2.13it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:15<00:00,  2.93it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import socket\n",
    "from Bio import Seq, SeqIO\n",
    "\n",
    "\n",
    "if 'biochem1' in socket.gethostname():\n",
    "    dataPBase = '/avicenna/vramani/analyses/pacbio/'\n",
    "    figPBase = '/avicenna/cmcnally/pbanalysis/'\n",
    "if 'assembler4' in socket.gethostname():\n",
    "    dataPBase = '/data/users/goodarzilab/colin/results/pacbio/'\n",
    "if 'wynton' in socket.gethostname():\n",
    "    dataPBase = '/wynton/group/goodarzilab/ramanilab/results/pacbio/'\n",
    "if 'rumi' in socket.gethostname():\n",
    "    raise Exception('no pacbio results folder on rumi')\n",
    "    \n",
    "    \n",
    "# CTCF sites\n",
    "# load in reference sequences for both the independent and dependent CTCF sites\n",
    "refFile = dataPBase + 'pbrun10_CTCFpool_2/snf2h_independent_site_observed.fasta'\n",
    "for ir, record in enumerate(SeqIO.parse(refFile, 'fasta')):\n",
    "    if ir > 0:\n",
    "        raise InputError('Reference fasta has multiple entries')\n",
    "    irefseq = record.seq # reference sequence for independent CTCF site\n",
    "refFile = dataPBase + 'pbrun10_CTCFpool_2/snf2h_dependent_site_observed.fasta'\n",
    "for ir, record in enumerate(SeqIO.parse(refFile, 'fasta')):\n",
    "    if ir > 0:\n",
    "        raise InputError('Reference fasta has multiple entries')\n",
    "    drefseq = record.seq # reference sequence for dependent CTCF site\n",
    "\n",
    "# Load in the sample reference tables for the CTCF site samples\n",
    "sampleRef = pd.read_csv(dataPBase + 'pbrun10_CTCFpool_2/pbrun10_CTCFpool_2.sampleReference.csv')\n",
    "sampleRef = pd.concat([sampleRef,\n",
    "                       pd.read_csv(dataPBase + 'pbrun10_CTCFpool_1/pbrun10_CTCFpool_1.sampleReference.csv')],\n",
    "                      ignore_index=True)\n",
    "sampleRef = pd.concat([sampleRef,\n",
    "                       pd.read_csv(dataPBase + '210516_NA_SNF2hCTCFarray_ST_rep2/210516_NA_SNF2hCTCFarray_ST_rep2.sampleReference.wynton.csv')],\n",
    "                      ignore_index=True)\n",
    "sampleRef = pd.concat([sampleRef,\n",
    "                       pd.read_csv(dataPBase + '210520_NA_SNF2hCTCFarray_MT_rep1/210520_NA_SNF2hCTCFarray_MT_rep1.sampleReference.wynton.csv')],\n",
    "                      ignore_index=True)\n",
    "sampleRef = pd.concat([sampleRef,\n",
    "                       pd.read_csv(dataPBase + '210608_NA_SNF2hCTCFarray_MT_rep2/210608_NA_SNF2hCTCFarray_MT_rep2.sampleReference.wynton.csv')],\n",
    "                      ignore_index=True)\n",
    "\n",
    "del sampleRef['index']\n",
    "\n",
    "indepSamples = np.nonzero([(name[0:5] == 'Indep' or name[0:8] == 'CTCF_Ind') for name in sampleRef['sampleName']])[0]\n",
    "depSamples = np.nonzero([(name[0:5] == 'Depen' or name[0:8] == 'CTCF_Dep') for name in sampleRef['sampleName']])[0]\n",
    "\n",
    "regionAll = pd.DataFrame()\n",
    "for samp in tqdm(indepSamples[2:], position=0):\n",
    "    regionFile = dataPBase + '{0}/processed/inaccessibleRegions/{0}_{1}_inacRegions.csv'.format(sampleRef['cell'][samp],\n",
    "                                                                                                sampleRef['sampleName'][samp])\n",
    "    regiondf = pd.read_csv(regionFile, index_col=0)\n",
    "\n",
    "    regiondf['mid'] = regiondf['start'] + (regiondf['end'] - regiondf['start']) / 2\n",
    "    regiondf['sample'] = samp\n",
    "    \n",
    "    regionAll = pd.concat([regionAll, regiondf])\n",
    "    \n",
    "regionAllInd = regionAll\n",
    "\n",
    "regionAll = pd.DataFrame()\n",
    "for samp in tqdm(depSamples[2:], position=0):\n",
    "    regionFile = dataPBase + '{0}/processed/inaccessibleRegions/{0}_{1}_inacRegions.csv'.format(sampleRef['cell'][samp],\n",
    "                                                                                                sampleRef['sampleName'][samp])\n",
    "    regiondf = pd.read_csv(regionFile, index_col=0)\n",
    "\n",
    "    regiondf['mid'] = regiondf['start'] + (regiondf['end'] - regiondf['start']) / 2\n",
    "    regiondf['sample'] = samp\n",
    "    \n",
    "    regionAll = pd.concat([regionAll, regiondf])\n",
    "    \n",
    "regionAllDep = regionAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [06:35<00:00, 14.12s/it]\n"
     ]
    }
   ],
   "source": [
    "sampleRef = pd.read_csv(dataPBase + 'sampleRef_K562_mESC.csv', sep=',')\n",
    "\n",
    "regionAll = pd.DataFrame()\n",
    "for samp in tqdm([4,5,8,9,14,15,20,21,22,23,24,25,26,27,32,33,34,35,36,37,38,40,41,42,44,45,46,48], position=0):\n",
    "    regionFile = dataPBase + '{0}/processed/inaccessibleRegions/{0}_{1}_inacRegions.csv'.format(sampleRef['cell'][samp],\n",
    "                                                                                                sampleRef['sampleName'][samp])\n",
    "    regiondf = pd.read_csv(regionFile, index_col=0)\n",
    "\n",
    "    regiondf['mid'] = regiondf['start'] + (regiondf['end'] - regiondf['start']) / 2\n",
    "    regiondf['sample'] = samp\n",
    "    \n",
    "    regionAll = pd.concat([regionAll, regiondf])\n",
    "    \n",
    "regionAllmESC = regionAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['font.sans-serif'] = \"Arial\"\n",
    "matplotlib.rcParams['font.family'] = \"sans-serif\"\n",
    "\n",
    "regiondf = {'mesc':regionAllmESC['length'],\n",
    "            'ind':regionAllInd['length'],\n",
    "            'dep':regionAllDep['length']}\n",
    "            \n",
    "divs = {'mesc': [50, 200, 370, 500, 630, 800, 970, 1090, 1200],\n",
    "        'ind': [70, 205, 340, 475, 610, 780, 950, 1120, 1300, 1500, 1650, 1770, 1980, 2170, 2350, 2520, 2660],\n",
    "        'dep': [70, 205, 345, 470, 605, 740, 880, 1005, 1175, 1320, 1500, 1740, 1890, 2035, 2180, 2310, 2480, 2740, 2870, 3000]}\n",
    "            \n",
    "refL = {'mesc': 3080,\n",
    "        'ind': 2706,\n",
    "        'dep': 3087}\n",
    "\n",
    "names = {'mesc': 'mESC',\n",
    "         'ind': 'S1',\n",
    "         'dep': 'S2'}\n",
    "    \n",
    "fig, ax = plt.subplots(3,1, figsize=(7,7), sharex=True, sharey=True)\n",
    "\n",
    "for imol, molecule in enumerate(['ind', 'dep', 'mesc']):\n",
    "\n",
    "\n",
    "    hist, bine = np.histogram(regiondf[molecule], bins=np.arange(-0.5, refL[molecule] + 0.5))\n",
    "    binc = bine[0:-1] + 0.5\n",
    "\n",
    "    hist = hist.astype('float')\n",
    "    ix = 0\n",
    "    while hist[ix] == 0:\n",
    "        hist[ix] = np.nan\n",
    "        ix += 1\n",
    "\n",
    "    smWidth = 21\n",
    "    smWidthH = int((smWidth-1) / 2)\n",
    "    smooths = []\n",
    "\n",
    "    \n",
    "    def smooth1time(inp):\n",
    "        smoothlast = inp.copy()\n",
    "        smoothn = inp.copy()\n",
    "        for windc in np.arange(0,refL[molecule])[np.isfinite(inp)]:\n",
    "            windlow = max(0, windc - smWidthH)\n",
    "            windhigh = min(refL[molecule], windc + smWidthH)\n",
    "            smoothn[windc] = np.nanmean(smoothlast[windlow:windhigh])\n",
    "        return smoothn\n",
    "\n",
    "    smoothc = hist.copy()\n",
    "    for i in range(10):\n",
    "        smoothc = smooth1time(smoothc)\n",
    "        smooths.append(smoothc)\n",
    "        \n",
    "\n",
    "    usesm = smooths[2]\n",
    "\n",
    "    ax[imol].plot(binc, np.log10(usesm))\n",
    "    usedivs = divs[molecule]\n",
    "    for p in usedivs:\n",
    "        ax[imol].axvline(x=p, ls='--', color='limegreen')\n",
    "    for i in range(len(usedivs)-1):\n",
    "        midp = usedivs[i] + (usedivs[i+1] - usedivs[i])/2\n",
    "        ax[imol].text(y=0, x=midp, s=str(i+1), ha='center')\n",
    "    # print the zero\n",
    "    midp = usedivs[0] - (usedivs[1] - usedivs[0])/2\n",
    "    ax[imol].text(y=0, x=midp, s='0', ha='center')\n",
    "    # print the max\n",
    "    midp = usedivs[-1] + (usedivs[-1] - usedivs[-2])/4\n",
    "    ax[imol].text(y=0, x=midp, s=str(len(usedivs))+'+', ha='left')\n",
    "    \n",
    "    ax[imol].set_title(names[molecule])\n",
    "ax[2].set_xlabel('Inaccessible region length')\n",
    "ax[2].set_ylabel('log$_{10}$( smoothed counts )')\n",
    "plt.tight_layout()\n",
    "\n",
    "fname = '/avicenna/cmcnally/pbanalysis/Figures/SAMOSA2_paper/nucCutoffs'\n",
    "\n",
    "plt.savefig(fname + '.png', dpi=300)\n",
    "plt.savefig(fname + '.svg', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py4",
   "language": "python",
   "name": "py4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
