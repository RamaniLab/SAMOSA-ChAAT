{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "import socket\n",
    "from scipy.stats import norm\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,3\" #don't use GPU because it's in use. Need to change this every time\n",
    "\n",
    "\n",
    "if 'biochem1' in socket.gethostname():\n",
    "    dataPBase = '/avicenna/vramani/analyses/pacbio/'\n",
    "    figPBase = '/avicenna/cmcnally/pbanalysis/'\n",
    "if 'titan' in socket.gethostname():\n",
    "    dataPBase = '/data/users/goodarzilab/colin/results/pacbio/'\n",
    "if 'wynton' in socket.gethostname():\n",
    "    dataPBase = '/wynton/group/goodarzilab/ramanilab/results/pacbio/'\n",
    "if 'rumi' in socket.gethostname():\n",
    "    raise Exception('no pacbio results folder on rumi')\n",
    "    \n",
    "sampleRef = pd.read_csv(dataPBase + 'sampleRef_K562_mESC.csv', sep=',', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate input formatted for tensorflow\n",
    "First, split up the full files into smaller blocks if they are too large. Then run the script formatNNinput.py on each block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split up full files for SAMv2\n",
    "import os\n",
    "\n",
    "usesamples = [39,43,47]\n",
    "\n",
    "zmwPerBlock = 50000\n",
    "\n",
    "for samp in usesamples:\n",
    "    with open(os.path.join(dataPBase, sampleRef['cell'][samp],'processed','full',\n",
    "                           sampleRef['cell'][samp] + '_' + sampleRef['sampleName'][samp] + '_full.pickle'), 'rb') as fin:\n",
    "        ipdfull = pickle.load(fin, encoding=\"latin1\")\n",
    "        \n",
    "    zmws = sorted(list(ipdfull.keys()))\n",
    "    \n",
    "    nBlock = int(np.ceil(len(zmws) / zmwPerBlock))\n",
    "    \n",
    "    for block in tqdm(np.arange(1,nBlock+1), position=0, desc=sampleRef['sampleName'][samp]):\n",
    "        ipdsub = {}\n",
    "        bstart = (block-1) * zmwPerBlock\n",
    "        bend = min(block * zmwPerBlock, len(zmws))\n",
    "        for zmw in zmws[bstart:bend]:\n",
    "            ipdsub[zmw] = ipdfull[zmw]\n",
    "        outfile = os.path.join(dataPBase, sampleRef['cell'][samp],'processed','full',\n",
    "                               sampleRef['cell'][samp] + '_' + sampleRef['sampleName'][samp] + '_full_block{:03d}.pickle'.format(block))\n",
    "        with open(outfile, 'wb') as fout:\n",
    "            pickle.dump(ipdsub, fout, pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "# check how many block files there are for each sample\n",
    "import glob\n",
    "\n",
    "usesamples = [39, 43, 47]\n",
    "nblock = {}\n",
    "for samp in usesamples:\n",
    "    gl = glob.glob(dataPBase + '{0}/processed/full/{0}_{1}_full_block*.pickle'.format(sampleRef['cell'][samp],\n",
    "                                                                                      sampleRef['sampleName'][samp]))\n",
    "    nblock[samp] = len(gl)\n",
    "    \n",
    "sampL = []\n",
    "blockL = []\n",
    "\n",
    "for samp in usesamples:\n",
    "    for block in np.arange(1,nblock[samp]+1):\n",
    "        sampL.append(samp)\n",
    "        blockL.append(block)\n",
    "        \n",
    "if not os.path.exists('/data/users/goodarzilab/colin/quickScripts'):\n",
    "    os.makedirs('/data/users/goodarzilab/colin/quickScripts')\n",
    "    \n",
    "    \n",
    "nScripts = 4\n",
    "perS = int(np.ceil(len(blockL)/nScripts))\n",
    "\n",
    "ix = 0\n",
    "\n",
    "for scriptN in range(nScripts):\n",
    "    with open('/data/users/goodarzilab/colin/quickScripts/makeNNinput_p{0}.sh'.format(scriptN), 'w') as fout:\n",
    "        fout.write('#!/usr/bin/zsh\\n\\n')\n",
    "        fout.write('source /data/users/goodarzilab/colin/.zshrc\\n\\n')\n",
    "        fout.write('conda activate NN2\\n\\n')\n",
    "        for ix in np.arange(scriptN*perS, min((scriptN+1)*perS, len(sampL))):\n",
    "            fout.write('python ~/code/scripts/formatNNinput.py {0} {1}\\n'.format(sampL[ix], blockL[ix]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train neural network components of the model\n",
    "First, a network to predict the IPD based on sequence context and non-adenine IPD percentiles in the molecule\n",
    "\n",
    "A cutoff of 0.42 on the residuals of the observed IPD minus these predictions defines methylation\n",
    "\n",
    "Second, a network to predict residuals in fully methylated controls, used to ignore sequence contexts that are rarely methylated\n",
    "\n",
    "Third, a model is trained to predict the probability of an adenine in a sequence context being predicted as methylated in fully methylated control DNA. Used as the HMM emmission probability for the accessible state\n",
    "\n",
    "Fourth, a model is trained to predict the probability of an adenine in a sequence context being predicted as methylated in unmethylated control DNA. Used as the HMM emmission probability for the inaccessible state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many adenines are in each sample?\n",
    "# for choosing how many adenines to use to train neural networks\n",
    "\n",
    "for samp in range(30):\n",
    "    try:\n",
    "        with np.load(os.path.join(dataPBase, sampleRef['cell'][samp],'processed','forNN',\n",
    "                                  sampleRef['cell'][samp] + '_' + sampleRef['sampleName'][samp] + '_forNN.npz')) as data:\n",
    "            na = data['sampleArr'].shape[0]\n",
    "        print('%02d: %s: %d' % (samp, sampleRef['sampleName'][samp], na))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def trainIPDmodel():\n",
    "    ### Load in unmethylated controls to train IPD model\n",
    "    usesamples = [6,7,10,11,12,13,16,17] #np.arange(8)\n",
    "    aPerSample = {samp:5000000 for samp in usesamples} #{2:5000000, 3:3000000, 6:5000000, 7:3000000} #{samp:2000000 for samp in usesamples}\n",
    "    ipdDat = []\n",
    "    sampDat = []\n",
    "    contextDat = []\n",
    "    percsDat = []\n",
    "    \n",
    "    for samp in tqdm(usesamples, position=0):\n",
    "        with np.load(os.path.join(dataPBase,\n",
    "                                  sampleRef['cell'][samp],'processed','forNN',\n",
    "                                  sampleRef['cell'][samp] + '_' + sampleRef['sampleName'][samp] + '_forNN.npz')) as data:\n",
    "            ipdDat.append(data['ipdArr'][0:aPerSample[samp],:])\n",
    "            sampDat.append(data['sampleArr'][0:aPerSample[samp],:])\n",
    "            contextDat.append(data['contextmat'][0:aPerSample[samp],:])\n",
    "            percsDat.append(data['percsmat'][0:aPerSample[samp],:][:,9:])\n",
    "\n",
    "    ipdDat = np.vstack(ipdDat)\n",
    "    sampDat = np.vstack(sampDat)\n",
    "    contextDat = np.vstack(contextDat)\n",
    "    percsDat = np.vstack(percsDat)\n",
    "\n",
    "    ### Create model to predict IPD\n",
    "    trainSet = np.nonzero(np.isin(sampDat, [6,10,11,12,16,17]))[0]\n",
    "    validSet = np.nonzero(np.isin(sampDat, [7,13]))[0]\n",
    "\n",
    "    context_inputs = keras.layers.Input(shape=contextDat.shape[1:])\n",
    "    perc_input = keras.layers.Input(shape=percsDat.shape[1:])\n",
    "    conc = keras.layers.concatenate([context_inputs, perc_input])\n",
    "    lay1 = keras.layers.Dense(200, activation=\"relu\", kernel_initializer='he_uniform')(conc)\n",
    "    lay2 = keras.layers.Dense(200, activation=\"relu\", kernel_initializer='he_uniform')(lay1)\n",
    "    lay3 = keras.layers.Dense(200, activation=\"relu\", kernel_initializer='he_uniform')(lay2)\n",
    "    lay4 = keras.layers.Dense(200, activation=\"relu\", kernel_initializer='he_uniform')(lay3)\n",
    "    outputs = keras.layers.Dense(1)(lay4)\n",
    "    ipdModel = keras.models.Model(inputs=[context_inputs, perc_input],\n",
    "                               outputs=[outputs])\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "    ipdModel.compile(loss=\"mean_squared_error\", optimizer=optimizer)\n",
    "\n",
    "    ### Train the model on negative control rep 1s, with rep 2s as validation data\n",
    "    early_stopping = EarlyStopping(patience = 2, restore_best_weights=True)\n",
    "\n",
    "    history = ipdModel.fit([contextDat[trainSet,:], percsDat[trainSet,:]], ipdDat[trainSet,:],\n",
    "                           epochs=20, batch_size=128, shuffle=True,\n",
    "                           validation_data=([contextDat[validSet,:], percsDat[validSet,:]], ipdDat[validSet,:]),\n",
    "                           callbacks=[early_stopping])\n",
    "    \n",
    "    return ipdModel\n",
    "\n",
    "ipdModel = trainIPDmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model to predict the residuals of fully methylated DNA based on sequence\n",
    "# Used to discriminate sequence contexts that are infrequently methylated\n",
    "def trainPosResidModel(ipdModel):\n",
    "    samp = 28\n",
    "    with np.load(os.path.join(dataPBase,sampleRef['cell'][samp],'processed','forNN',\n",
    "                              sampleRef['cell'][samp] + '_' + sampleRef['sampleName'][samp] + '_forNN.npz')) as data:\n",
    "        ipdDat = data['ipdArr']\n",
    "        #sampDat.append(data['sampleArr'][0:aPerSample[samp],:])\n",
    "        contextDat = data['contextmat']\n",
    "        percsDat = data['percsmat'][:,9:]\n",
    "\n",
    "    predIPD = ipdModel.predict([contextDat, percsDat], batch_size=2048)\n",
    "    resid = ipdDat - predIPD\n",
    "\n",
    "    trainSet = np.arange(ipdDat.shape[0])\n",
    "    np.random.shuffle(trainSet)\n",
    "    print(trainSet[0:10])\n",
    "    validSet = trainSet[30000000:40000000]\n",
    "    trainSet = trainSet[0:20000000]\n",
    "    \n",
    "    context_inputs = keras.layers.Input(shape=contextDat.shape[1:])\n",
    "    lay1 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer='he_uniform')(context_inputs)\n",
    "    lay2 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer='he_uniform')(lay1)\n",
    "    lay3 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer='he_uniform')(lay2)\n",
    "    outputs = keras.layers.Dense(1)(lay3)\n",
    "    posResidModel = keras.models.Model(inputs=[context_inputs],\n",
    "                               outputs=[outputs])\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "    posResidModel.compile(loss=\"mean_squared_error\", optimizer=optimizer)\n",
    "\n",
    "    history = posResidModel.fit([contextDat[trainSet,:]], resid[trainSet,:],\n",
    "                                epochs=2, batch_size=128, shuffle=True,\n",
    "                                validation_data=([contextDat[validSet,:]], resid[validSet,:]))\n",
    "    \n",
    "    return posResidModel\n",
    "\n",
    "posResidModel = trainPosResidModel(ipdModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = 4\n",
    "ipdModel = keras.models.load_model(dataPBase + '%s/processed/NNmodels/ipdModel' % (sampleRef['cell'][samp]))\n",
    "posResidModel = keras.models.load_model(dataPBase + '%s/processed/NNmodels/posResidualModel' % (sampleRef['cell'][samp]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model to predict the probability of a adenine being called as methylated in pos control\n",
    "def trainPosProbModel(ipdModel, posResidModel):\n",
    "    samp = 28\n",
    "    with np.load(os.path.join(dataPBase,sampleRef['cell'][samp],'processed','forNN',\n",
    "                              sampleRef['cell'][samp] + '_' + sampleRef['sampleName'][samp] + '_forNN.npz')) as data:\n",
    "        ipdDat = data['ipdArr']\n",
    "        #sampDat.append(data['sampleArr'][0:aPerSample[samp],:])\n",
    "        contextDat = data['contextmat']\n",
    "        percsDat = data['percsmat'][:,9:]\n",
    "\n",
    "    predIPD = ipdModel.predict([contextDat, percsDat], batch_size=65536)\n",
    "    resid = ipdDat - predIPD\n",
    "    \n",
    "    methPred = resid > 0.42\n",
    "    \n",
    "    resPred = posResidModel.predict([contextDat], batch_size=65536)\n",
    "    \n",
    "    userp = np.nonzero(resPred > 0.6)[0]\n",
    "    print(userp.shape)\n",
    "    np.random.shuffle(userp)\n",
    "    trainSet = userp[0:int(len(userp) * .75)]\n",
    "    validSet = userp[int(len(userp) * .8):int(len(userp) * .99)]\n",
    "    print(trainSet.shape)\n",
    "    print(validSet.shape)\n",
    "    \n",
    "    context_inputs = keras.layers.Input(shape=contextDat.shape[1:])\n",
    "    lay1 = keras.layers.Dense(200, activation=\"relu\", kernel_initializer='he_uniform')(context_inputs)\n",
    "    lay2 = keras.layers.Dense(200, activation=\"relu\", kernel_initializer='he_uniform')(lay1)\n",
    "    lay3 = keras.layers.Dense(200, activation=\"relu\", kernel_initializer='he_uniform')(lay2)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(lay3)\n",
    "    posProbModel = keras.models.Model(inputs=[context_inputs],\n",
    "                               outputs=[outputs])\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "    posProbModel.compile(loss=\"binary_crossentropy\", optimizer=optimizer)\n",
    "\n",
    "    for bsize in [256, 1024, 4096, 16384, 32768, 65536, 131072]:\n",
    "        history = posProbModel.fit([contextDat[trainSet,:]], methPred[trainSet,:],\n",
    "                                    epochs=1, batch_size=bsize, shuffle=True,\n",
    "                                    validation_data=([contextDat[validSet,:]],\n",
    "                                                     methPred[validSet,:]))\n",
    "    \n",
    "    return posProbModel\n",
    "    \n",
    "posProbModel = trainPosProbModel(ipdModel, posResidModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model to predict the probability of a adenine being called as methylated in neg controls\n",
    "def trainNegProbModel(ipdModel, posResidModel):\n",
    "    usesamples = [6,11,13,16] #np.arange(8)\n",
    "    aPerSample = {samp:12500000 for samp in usesamples} #{2:5000000, 3:3000000, 6:5000000, 7:3000000} #{samp:2000000 for samp in usesamples}\n",
    "    ipdDat = []\n",
    "    contextDat = []\n",
    "    percsDat = []\n",
    "    \n",
    "    for samp in tqdm(usesamples, position=0):\n",
    "        with np.load(os.path.join(dataPBase,\n",
    "                                  sampleRef['cell'][samp],'processed','forNN',\n",
    "                                  sampleRef['cell'][samp] + '_' + sampleRef['sampleName'][samp] + '_forNN.npz')) as data:\n",
    "            ipdDat.append(data['ipdArr'][0:aPerSample[samp],:])\n",
    "            contextDat.append(data['contextmat'][0:aPerSample[samp],:])\n",
    "            percsDat.append(data['percsmat'][0:aPerSample[samp],:][:,9:])\n",
    "\n",
    "    ipdDat = np.vstack(ipdDat)\n",
    "    contextDat = np.vstack(contextDat)\n",
    "    percsDat = np.vstack(percsDat)\n",
    "    print('Finished loading')\n",
    "    \n",
    "    predIPD = ipdModel.predict([contextDat, percsDat], batch_size=65536)\n",
    "    resid = ipdDat - predIPD\n",
    "    \n",
    "    methPred = resid > 0.42\n",
    "    \n",
    "    resPred = posResidModel.predict([contextDat], batch_size=65536)\n",
    "    \n",
    "    userp = np.nonzero(resPred > 0.6)[0]\n",
    "    print(userp.shape)\n",
    "    \n",
    "    trainSet = userp[0:int(len(userp) * .75)]\n",
    "    validSet = userp[int(len(userp) * .8):int(len(userp) * .99)]\n",
    "    print(trainSet.shape)\n",
    "    print(validSet.shape)\n",
    "    \n",
    "    context_inputs = keras.layers.Input(shape=contextDat.shape[1:])\n",
    "    lay1 = keras.layers.Dense(200, activation=\"relu\", kernel_initializer='he_uniform')(context_inputs)\n",
    "    lay2 = keras.layers.Dense(200, activation=\"relu\", kernel_initializer='he_uniform')(lay1)\n",
    "    lay3 = keras.layers.Dense(200, activation=\"relu\", kernel_initializer='he_uniform')(lay2)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(lay3)\n",
    "    negProbModel = keras.models.Model(inputs=[context_inputs],\n",
    "                               outputs=[outputs])\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "    negProbModel.compile(loss=\"binary_crossentropy\", optimizer=optimizer)\n",
    "\n",
    "    for bsize in [256, 1024, 4096, 16384, 32768, 65536, 131072]:\n",
    "        history = negProbModel.fit([contextDat[trainSet,:]], methPred[trainSet,:],\n",
    "                                    epochs=1, batch_size=bsize, shuffle=True,\n",
    "                                    validation_data=([contextDat[validSet,:]],\n",
    "                                                     methPred[validSet,:]))\n",
    "    \n",
    "    return negProbModel\n",
    "    \n",
    "negProbModel = trainNegProbModel(ipdModel, posResidModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = 4\n",
    "if not os.path.exists(dataPBase + '%s/processed/NNmodels' % (sampleRef['cell'][samp])):\n",
    "    os.makedirs(dataPBase + '%s/processed/NNmodels' % (sampleRef['cell'][samp]))\n",
    "ipdModel.save(dataPBase + '%s/processed/NNmodels/ipdModel' % (sampleRef['cell'][samp]))\n",
    "posResidModel.save(dataPBase + '%s/processed/NNmodels/posResidualModel' % (sampleRef['cell'][samp]))\n",
    "posProbModel.save(dataPBase + '%s/processed/NNmodels/posProbModel' % (sampleRef['cell'][samp]))\n",
    "negProbModel.save(dataPBase + '%s/processed/NNmodels/negProbModel' % (sampleRef['cell'][samp]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out the HMM input for each molecule\n",
    "Uses the above trained models to predict methylation, get probabiltiy of methylation if the base was accessible or inaccessible, and filters out rarely methylated sequence contexts. Writes this input into a pickle file that will be loaded by runAccessibilityHMM.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data formatted for HMM application\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "samp = 4\n",
    "ipdModel = keras.models.load_model(dataPBase + '%s/processed/NNmodels/ipdModel' % (sampleRef['cell'][samp]))\n",
    "posResidModel = keras.models.load_model(dataPBase + '%s/processed/NNmodels/posResidualModel' % (sampleRef['cell'][samp]))\n",
    "posProbModel = keras.models.load_model(dataPBase + '%s/processed/NNmodels/posProbModel' % (sampleRef['cell'][samp]))\n",
    "negProbModel = keras.models.load_model(dataPBase + '%s/processed/NNmodels/negProbModel' % (sampleRef['cell'][samp]))\n",
    "\n",
    "\n",
    "def makeHMMinput(samp):\n",
    "    with open(dataPBase + '%s/processed/full/%s_%s_full_zmwinfo.pickle' %\n",
    "              (sampleRef['cell'][samp], sampleRef['cell'][samp], sampleRef['sampleName'][samp]), 'rb') as fin:\n",
    "        zmwinfo = pickle.load(fin, encoding=\"latin1\")\n",
    "\n",
    "    parts = sorted(glob(os.path.join(dataPBase,sampleRef['cell'][samp],'processed','forNN',\n",
    "                                     sampleRef['cell'][samp] + '_' + \n",
    "                                     sampleRef['sampleName'][samp] + '_forNN*.npz')))\n",
    "\n",
    "    pieceN = 0\n",
    "\n",
    "    if not os.path.exists(dataPBase + '%s/processed/forHMM' % (sampleRef['cell'][samp])):\n",
    "            os.makedirs(dataPBase + '%s/processed/forHMM' % (sampleRef['cell'][samp]))\n",
    "\n",
    "    for inputPart in tqdm(parts, position=0, desc=sampleRef['sampleName'][samp]):\n",
    "        with np.load(inputPart) as data:\n",
    "            ipdDat = data['ipdArr']\n",
    "            contextDat = data['contextmat']\n",
    "            percsDat = data['percsmat'][:,9:]\n",
    "            zmwDat = data['zmwArr']\n",
    "            zmwPosDat = data['zmwPos']\n",
    "\n",
    "        predIPD = ipdModel.predict([contextDat, percsDat], batch_size=131072)\n",
    "        resid = ipdDat - predIPD\n",
    "\n",
    "        methPred = resid > 0.42\n",
    "\n",
    "        resPred = posResidModel.predict([contextDat], batch_size=131072)\n",
    "\n",
    "        posProb = posProbModel.predict([contextDat], batch_size=131072)\n",
    "        negProb = negProbModel.predict([contextDat], batch_size=131072)\n",
    "\n",
    "        usePred = np.nonzero(resPred > 0.6)[0] \n",
    "\n",
    "        hmmInput = {}\n",
    "        ia = 0\n",
    "\n",
    "        while ia < resPred.shape[0]:\n",
    "            zmw = zmwDat[ia,0]\n",
    "            istart = ia\n",
    "            while ia < resPred.shape[0] and zmwDat[ia,0] == zmw:\n",
    "                ia += 1\n",
    "            iend = ia - 1\n",
    "\n",
    "            zmwInd = np.arange(istart, iend + 1)\n",
    "            goodInd = zmwInd[resPred[zmwInd,0] > 0.6]\n",
    "            goodDat = pd.DataFrame({'pos':zmwPosDat[goodInd, 0], 'methPred':methPred[goodInd, 0], 'posProb':posProb[goodInd, 0],\n",
    "                          'negProb':negProb[goodInd, 0]})\n",
    "            goodDat.sort_values(axis=0, by='pos', inplace=True)\n",
    "            goodDat.reset_index(inplace=True)\n",
    "\n",
    "            if goodDat.shape[0] >= 2:\n",
    "                hmmInput[zmw] = {'inDat':goodDat,\n",
    "                                 'cclen':zmwinfo['cclen'][zmwinfo['zmw'] == zmw].iloc[0]}\n",
    "\n",
    "            if len(list(hmmInput.keys())) >= 2000 or ia == resPred.shape[0]:\n",
    "                with open(dataPBase + '{0}/processed/forHMM/{0}_{1}_forHMM_piece{2:05d}.pickle'.format(sampleRef['cell'][samp],\n",
    "                                                                                                   sampleRef['sampleName'][samp],\n",
    "                                                                                                   pieceN), 'wb') as fout:\n",
    "                    pickle.dump(hmmInput, fout, protocol=4)\n",
    "                pieceN += 1\n",
    "                hmmInput = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usesamples = [39,43,47]\n",
    "\n",
    "for samp in usesamples:\n",
    "    makeHMMinput(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write scripts of all pieces of all samples\n",
    "from glob import glob\n",
    "\n",
    "with open('/data/users/goodarzilab/colin/code/scripts/doHMM.sh', 'w') as fout:\n",
    "    for samp in [39,43,47]:\n",
    "        pieces = glob(os.path.join(dataPBase,sampleRef['cell'][samp],'processed','forHMM',\n",
    "                              sampleRef['cell'][samp] + '_' + \n",
    "                              sampleRef['sampleName'][samp] + '_forHMM_piece*.pickle'))\n",
    "        ipiece = 0\n",
    "        for p in pieces:\n",
    "            fout.write('qsub /wynton/home/goodarzi/cpmcnally/code/scripts/shellRunAccessibilityHMM.sh {0} {1}\\n'.format(samp,\n",
    "                                                                                                                        ipiece))\n",
    "            ipiece += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NN2]",
   "language": "python",
   "name": "conda-env-NN2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
